{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "import regex as re\n",
    "from langdetect import detect\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import inflect #convert the numbers into words\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "#from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, you must pre-process all the information collected for each book by\n",
    "\n",
    "1. Removing stopwords\n",
    "2. Removing punctuation\n",
    "3. Stemming\n",
    "4. Anything else you think it's needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you survive on your own in the wild, with every one out to make sure you don't live to see the morning?In the ruins of a place once known as North America lies the nation of Panem, a shining Capitol surrounded by twelve outlying districts. The Capitol is harsh and cruel and keeps the districts in line by forcing them all to send one boy and one girl between the ages of twelve and eighteen to participate in the annual Hunger Games, a fight to the death on live TV.Sixteen-year-old Katniss Everdeen, who lives alone with her mother and younger sister, regards it as a death sentence when she steps forward to take her sister's place in the Games. But Katniss has been close to dead before—and survival, for her, is second nature. Without really meaning to, she becomes a contender. But if she is to win, she will have to start making choices that weight survival against humanity and life against love.\n",
      "['could', 'surviv', 'wild', 'everi', 'one', 'make', 'sure', 'dont', 'live', 'see', 'morningin', 'ruin', 'place', 'known', 'north', 'america', 'lie', 'nation', 'panem', 'shine', 'capitol', 'surround', 'twelv', 'outli', 'district', 'capitol', 'harsh', 'cruel', 'keep', 'district', 'line', 'forc', 'send', 'one', 'boy', 'one', 'girl', 'age', 'twelv', 'eighteen', 'particip', 'annual', 'hunger', 'game', 'fight', 'death', 'live', 'tvsixteenyearold', 'katniss', 'everdeen', 'live', 'alon', 'mother', 'younger', 'sister', 'regard', 'death', 'sentenc', 'step', 'forward', 'take', 'sister', 'place', 'game', 'katniss', 'close', 'dead', 'before—and', 'surviv', 'second', 'natur', 'without', 'realli', 'mean', 'becom', 'contend', 'win', 'start', 'make', 'choic', 'weight', 'surviv', 'human', 'life', 'love']\n"
     ]
    }
   ],
   "source": [
    "def preprocessing_text(plot):\n",
    "    \"\"\"\n",
    "    Function to pre-process text, returns the text filtered by stopwords, punctuactions and so on \n",
    "    Input: .tsv files\n",
    "    Output: list(bag of words)\n",
    "    \"\"\"  \n",
    "    article_new = \" \" #str(plot)\n",
    "    \n",
    "    #lower case \n",
    "    article_new = plot.lower()\n",
    "    \n",
    "    # Remove numbers \n",
    "    article_new = re.sub(r'\\d+', '', str(article_new))\n",
    "    \n",
    "    # remove punctuation\n",
    "    \n",
    "    #translator = str.maketrans('', '', string.punctuation)\n",
    "    #article_new = article_new.translate(translator)\n",
    "    \n",
    "    article_new = \"\".join([char for char in article_new if char not in string.punctuation])\n",
    "    \n",
    "    ## remove whitespace from text \n",
    "    article_new =  \" \".join(article_new.split())  #singolo spazio\n",
    "    \n",
    "    ## remove stopwords function\n",
    "    stop_words = set(stopwords.words(\"english\")) \n",
    "    word_tokens = word_tokenize(str(article_new)) \n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words] \n",
    "    article_new = filtered_text \n",
    "    \n",
    "    \n",
    "    ## stem words in the list of tokenised words \n",
    "    #stemmer = PorterStemmer()\n",
    "    #word_tokens = word_tokenize(str(article_new)) \n",
    "    #stems = [stemmer.stem(word) for word in word_tokens] \n",
    "    #article_new = stems\n",
    "\n",
    "    porter = PorterStemmer()\n",
    "    article_new = [porter.stem(word) for word in article_new]\n",
    "        \n",
    "    return article_new\n",
    "\n",
    "######################\n",
    "article_new = \"\"\n",
    "\n",
    "article = pd.read_csv('E:\\\\HW3\\\\Articles\\\\article_1.tsv',delimiter='\\t',encoding='cp1252')\n",
    "article = article.columns        \n",
    "plot = article[6]\n",
    "print(plot)\n",
    "\n",
    "preprocessing_text(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocabulary\n",
    "\n",
    "def vocabulary(plot):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to create the vocabulary that maps each word to an integer \n",
    "    Input: plot\n",
    "    Output: file vocabulary.csv\n",
    "    \"\"\"\n",
    "    \n",
    "    vocabulary_set = []\n",
    "    vocabulary_dict = {}\n",
    "    \n",
    "    \n",
    "    article = pd.read_csv('E:\\\\HW3\\\\Articles\\\\article_1.tsv',delimiter='\\t',encoding='cp1252')\n",
    "    article = article.columns        \n",
    "    plot = article[6]\n",
    "    \n",
    "    \n",
    "    article_new = preprocessing_text(plot)\n",
    "    vocabulary_set = vocabulary_set + article_new\n",
    "    vocabulary_def = set(vocabulary_set)\n",
    "    \n",
    "    index = 1\n",
    "    \n",
    "    for parola in vocabulary_def:\n",
    "        #if parola not in vocabulary_def.keys(): # non credo sia necessario\n",
    "        vocabulary_dict[parola] = index\n",
    "        index +=1\n",
    "        \n",
    "        \n",
    "    return vocabulary_dict\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverted Index\n",
    "\n",
    "def Inverted_Index(vocabulary_dict, article):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to create the inverted index  \n",
    "    Input: vocabulary_dict and articles\n",
    "    Output: dictionary with Inverted Index\n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "    doc_list = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
