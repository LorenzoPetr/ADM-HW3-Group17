{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from langdetect import detect\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup = BeautifulSoup(open(\"Best Books Ever (53139 books).html\"), features=\"lxml\") \n",
    "#not convenient.. let's try to load the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 1.1\n",
    "\n",
    "web_page = requests.get(\"https://www.goodreads.com/list/show/1.Best_Books_Ever?page=1\")\n",
    "\n",
    "def get_url(url):\n",
    "    req = urllib.request.Request(url)\n",
    "    return urllib.request.urlopen(req)\n",
    "\n",
    "def listToString(s):  \n",
    "    \n",
    "    # initialize an empty string \n",
    "    str1 = \"\\n\"\n",
    "    # return string   \n",
    "    return (str1.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 151\n",
    "books_urls = []\n",
    "while (page>=151 and page <= 300):\n",
    "    web_page = requests.get(\"https://www.goodreads.com/list/show/1.Best_Books_Ever?page={}\".format(page))\n",
    "    soup = BeautifulSoup(web_page.content, features=\"lxml\")\n",
    "    for link in soup.find_all('a', class_='bookTitle', itemprop = 'url', href = True):\n",
    "        url = link.get('href')\n",
    "        url = \"https://www.goodreads.com/\"+url\n",
    "        books_urls.append(url)\n",
    "    #book_links = print_book_links(soup)\n",
    "    str_book_links = listToString(books_urls)\n",
    "    page+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str_book_links #it looks orrible now.. but the file will be written correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all links found into a file.txt\n",
    "f = open(\"BookLinks.txt\", \"w\")\n",
    "f.write(str_book_links)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 1.2\n",
    "\n",
    "page = 233\n",
    "htmls = []\n",
    "while (page>= 233 and page <= 300):\n",
    "    \n",
    "    directory = \"HTMLSources_Page\"+str(page)\n",
    "    parent_dir = \"/home/lorenzo/Documents/UniversitÃ /1Â° Term/Algorithmic Methods of Data Mining/LAB/Homeworks/HW3\"\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    os.mkdir(path)\n",
    "    \n",
    "    web_page = requests.get(\"https://www.goodreads.com/list/show/1.Best_Books_Ever?page={}\".format(page))\n",
    "    soup = BeautifulSoup(web_page.content, features=\"lxml\")\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    for link in soup.find_all('a', class_='bookTitle', itemprop = 'url', href = True):\n",
    "        url = link.get('href')\n",
    "        url = \"https://www.goodreads.com/\"+url\n",
    "        html = urllib.request.urlopen(url).read()\n",
    "        html_formatted = html.decode(\"utf-8\")\n",
    "        \n",
    "        namefile = \"Book\"+str(i)+\"_\"+\"Page\"+str(page)\n",
    "        with open(os.path.join(path,namefile), 'w') as f:\n",
    "            f.write(str(html_formatted))\n",
    "            f.close()\n",
    "        i += 1\n",
    "    \n",
    "    page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  \n",
      "      The Greek Myths: 1\n",
      "\n",
      "Series:  \n",
      "        (The Greek Myths #1)\n",
      "\n",
      "Author:  Robert Graves\n",
      "Rating Value:  \n",
      "  4.08\n",
      "\n",
      "Rating Count:  \n",
      "  1,236\n",
      "  ratings\n",
      "\n",
      "Plot:  In a work that has become a classic reference book for both the serious scholar and the casual inquirer, Graves retells the adventures of the important gods and heroes worshipped by the ancient Greeks. Each entry provides a full commentary which examines problems of interpretation in both historical and anthropological terms, and in light of contemporary research.\n",
      "Number of Pages:  370 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        December 1st 1990\n",
      "         by Penguin Books\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      The Measure of a Man: A Spiritual Autobiography\n",
      "\n",
      "Series:  Edit Details\n",
      "Author:  Sidney Poitier\n",
      "Rating Value:  \n",
      "  3.72\n",
      "\n",
      "Rating Count:  \n",
      "  10,116\n",
      "  ratings\n",
      "\n",
      "Plot:  In this luminous memoir, a true American icon looks back on his celebrated life and career.Â  His body of work is arguable the most morally significant in cinematic history, and the power and influence of that work are indicative of the character of the man behind the many storied roles. Here, Sidney Poitier explores these elements of character and personal values to take h\n",
      "Number of Pages:  243 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        January 26th 2007\n",
      "         by HarperOne\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      Silent Pantheon\n",
      "\n",
      "Series:  Edit Details\n",
      "Author:  Eric Nierstedt\n",
      "Rating Value:  \n",
      "  4.27\n",
      "\n",
      "Rating Count:  \n",
      "  233\n",
      "  ratings\n",
      "\n",
      "Plot:  \n",
      "Number of Pages:  267 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        July 1st 2019\n",
      "         by Eric Nierstedt\n",
      "\n",
      "      \n",
      "Title:  \n",
      "      The Element: How Finding Your Passion Changes Everything\n",
      "\n",
      "Series:  Edit Details\n",
      "Author:  Ken Robinson\n",
      "Rating Value:  \n",
      "  3.89\n",
      "\n",
      "Rating Count:  \n",
      "  14,905\n",
      "  ratings\n",
      "\n",
      "Plot:  From one of the world's leading thinkers and speakers on creativity and self-fulfillment, a breakthrough book about talent, passion, and achievement  The element is the point at which natural talent meets personal passion. When people arrive at the element, they feel most themselves and most inspired and achieve at their highest levels. \"The Element\" draws on the stories of\n",
      "Number of Pages:  274 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        January 8th 2009\n",
      "         by Viking Books\n",
      "\n",
      "      \n",
      "Title:  \n",
      "      The Person Controller\n",
      "\n",
      "Series:  \n",
      "        (The Blockbuster Baddiel Box)\n",
      "\n",
      "Author:  David Baddiel\n",
      "Rating Value:  \n",
      "  4.36\n",
      "\n",
      "Rating Count:  \n",
      "  1,261\n",
      "  ratings\n",
      "\n",
      "Plot:  \n",
      "Number of Pages:  385 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        October 8th 2015\n",
      "         by HarperCollinsChildrenâ€™sBooks\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      The Grand Tour\n",
      "\n",
      "Series:  \n",
      "        (Cecelia and Kate #2)\n",
      "\n",
      "Author:  Patricia C. Wrede\n",
      "Rating Value:  \n",
      "  3.67\n",
      "\n",
      "Rating Count:  \n",
      "  6,594\n",
      "  ratings\n",
      "\n",
      "Plot:  Kate and Cecy and their new husbands, Thomas and James, are off on a leisurely tour of the Continent. But once they arrive in France, strange things start to happen. Cecy receives a mysterious package, Thomas's valet is assaulted, and Kate loses a glove. Soon it becomes clear that the newlyweds have stumbled upon a magical plot to take over Europe, and they must embark on \n",
      "Number of Pages:  469 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        April 1st 2006\n",
      "         by HMH Books for Young Readers\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      Complete Shorter Fiction\n",
      "\n",
      "Series:  Edit Details\n",
      "Author:  Oscar Wilde\n",
      "Rating Value:  \n",
      "  4.15\n",
      "\n",
      "Rating Count:  \n",
      "  2,708\n",
      "  ratings\n",
      "\n",
      "Plot:  For the first time in one volume, this complete collection of all the short fiction Oscar Wilde published contains such social and literary parodies as \"Lord Arthur Savile's Crime\" and \"The Canterville Ghost;\" such well-known fairy tales as \"The Happy Prince,\" \"The Young King,\" and \"The Fisherman and his Soul;\" an imaginary portrait of the dedicatee of Shakespeare's Sonnet\n",
      "Number of Pages:  288 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        March 5th 1998\n",
      "         by Oxford University Press\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      The Rosary\n",
      "\n",
      "Series:  Edit Details\n",
      "Author:  Florence Louisa Barclay\n",
      "Rating Value:  \n",
      "  3.99\n",
      "\n",
      "Rating Count:  \n",
      "  1,206\n",
      "  ratings\n",
      "\n",
      "Plot:  \"The Rosary\" is a beautiful love story. Gareth Dalmain falls in love with the Honorable Jane Champion. She loves him back, but does not trust his love, as is known to be a great lover of beauty, and she - alas - is very plain. Just as she decides to trust him, she receives news that he has been blinded in a hunting accident. She wants to go visit him, but he will not recei\n",
      "Number of Pages:  380 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        April 1st 2005\n",
      "         by Kessinger Publishing\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      Sunrise\n",
      "\n",
      "Series:  \n",
      "        (Sunrise #1)\n",
      "\n",
      "Author:  Karen Kingsbury\n",
      "Rating Value:  \n",
      "  4.37\n",
      "\n",
      "Rating Count:  \n",
      "  8,624\n",
      "  ratings\n",
      "\n",
      "Plot:  In preparation for their long-awaited wedding day, Dayne and Katy are determined to keep the ceremony a secret from the paparazzi. Their relationship grows closer and stronger as they plan together, but in the end it takes the help of the Baxter family and many of the CKT kids so that they'll even have a chance at a private wedding. John Baxter is thrilled that his oldest \n",
      "Number of Pages:  301 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        May 8th 2007\n",
      "         by Tyndale House Publishers\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      Flappers and Philosophers\n",
      "\n",
      "Series:  Edit Details\n",
      "Author:  F. Scott Fitzgerald\n",
      "Rating Value:  \n",
      "  4.00\n",
      "\n",
      "Rating Count:  \n",
      "  4,616\n",
      "  ratings\n",
      "\n",
      "Plot:  By the Irish American Jazz Age novelist and short story writer regarded as one of the greatest American writers of the twentieth century. He was the self-styled spokesman of the \"Lost Generation\" and author of The Great Gatsby (1925). His debut novel, This Side of Paradise (1920) examines the lives and morality of post-World War I youth. Flappers and Philosophers (1920) wa\n",
      "Number of Pages:  269 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        1920\n",
      "         by Charles Scribner's Sons\n",
      "\n",
      "      \n",
      "Title:  \n",
      "      Runaways Deluxe, Vol. 1\n",
      "\n",
      "Series:  \n",
      "        (Runaways: The Complete Collection #1)\n",
      "\n",
      "Author:  Brian K. Vaughan\n",
      "Rating Value:  \n",
      "  4.20\n",
      "\n",
      "Rating Count:  \n",
      "  11,557\n",
      "  ratings\n",
      "\n",
      "Plot:  In Pride & Joy, six young friends discover their parents are all secretly super-powered villains Finding strength in one another, the shocked teens run away from home and straight into the adventure of their lives - vowing to turn the tables on their evil legacy. In Teenage Wasteland, the Runaways find a kindred spirit in a daring young stranger and welcome him into their \n",
      "Number of Pages:  448 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        August 9th 2006\n",
      "         by Marvel\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      Leven Thumps and the Wrath of Ezra\n",
      "\n",
      "Series:  \n",
      "        (Leven Thumps #4)\n",
      "\n",
      "Author:  Obert Skye\n",
      "Rating Value:  \n",
      "  3.98\n",
      "\n",
      "Rating Count:  \n",
      "  9,363\n",
      "  ratings\n",
      "\n",
      "Plot:  4th Volume in the Levem Thumps Series. Leven continues quest to save the imaginations and dreams of all mankind\n",
      "Number of Pages:  400 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        October 1st 2008\n",
      "         by Shadow Mountain\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      Y: The Last Man, Vol. 10: Whys and Wherefores\n",
      "\n",
      "Series:  \n",
      "        (Y: The Last Man #10)\n",
      "\n",
      "Author:  Brian K. Vaughan\n",
      "Rating Value:  \n",
      "  4.33\n",
      "\n",
      "Rating Count:  \n",
      "  22,762\n",
      "  ratings\n",
      "\n",
      "Plot:   \n",
      "Number of Pages:  168 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        July 1st 2008\n",
      "         by Vertigo\n",
      "\n",
      "      \n",
      "Title:  \n",
      "      Galway Bay\n",
      "\n",
      "Series:  \n",
      "        (Of Irish Blood #1)\n",
      "\n",
      "Author:  Mary Pat Kelly\n",
      "Rating Value:  \n",
      "  4.14\n",
      "\n",
      "Rating Count:  \n",
      "  4,254\n",
      "  ratings\n",
      "\n",
      "Plot:  In a hidden Ireland where fishermen and tenant farmers find solace in their ancient faith, songs, stories, and communal celebrations, young Honora Keeley and Michael Kelly wed and start a family. Because they and their countrymen must sell both their catch and their crops to pay exorbitant rents, potatoes have become their only staple food. But when blight destroys the pota\n",
      "Number of Pages:  551 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        February 9th 2009\n",
      "         by Grand Central Publishing\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      If God Is Love: Rediscovering Grace in an Ungracious World\n",
      "\n",
      "Series:  \n",
      "        (Grace Series  #2)\n",
      "\n",
      "Author:  Philip Gulley\n",
      "Rating Value:  \n",
      "  4.30\n",
      "\n",
      "Rating Count:  \n",
      "  581\n",
      "  ratings\n",
      "\n",
      "Plot:  If God is love, why are so many Christians fearful, and why do so many church leaders sound hateful? Two controversial pastors address issues the church wonâ€²t face, calling us to restore grace as the center of the Christian life. o In If Grace Is True, Pastors Philip Gulley and James Mulholland revealed their belief that God will save every person. They now explore the impl\n",
      "Number of Pages:  320 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        October 11th 2005\n",
      "         by HarperOne\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      The Last Leopard\n",
      "\n",
      "Series:  \n",
      "        (Animal Healer #3)\n",
      "\n",
      "Author:  Lauren St. John\n",
      "Rating Value:  \n",
      "  4.21\n",
      "\n",
      "Rating Count:  \n",
      "  1,369\n",
      "  ratings\n",
      "\n",
      "Plot:  Martine is looking forward to the holidays and riding Jemmy, her white giraffe, until an accident sends her and Ben on a journey to the Matobo Hills wilderness in Zimbabwe. It is a lawless land, where nothing is as it seems. When they uncover a plot in which the fate of a magnificent leopard and the lost treasure of an African King are mysteriously linked, their friendship\n",
      "Number of Pages:  208 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        August 1st 2008\n",
      "         by Orion\n",
      "\n",
      "      \n",
      "Title:  \n",
      "      Election\n",
      "\n",
      "Series:  Edit Details\n",
      "Author:  Tom Perrotta\n",
      "Rating Value:  \n",
      "  3.86\n",
      "\n",
      "Rating Count:  \n",
      "  7,463\n",
      "  ratings\n",
      "\n",
      "Plot:  A suburban New Jersey high school teacher confronts a student-body election gone haywire in this darkly comic novel by the author of The Wishbones. Scheduled for release as a feature film in 1998, starring Matthew Broderick.Who really cares who gets elected President of Winwood High School? Nobody -- except Tracy Flick. Tracy's one of those students of boundless energy and\n",
      "Number of Pages:  200 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        October 1st 1998\n",
      "         by Berkley Books\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      Panggil Aku Kartini Saja\n",
      "\n",
      "Series:  Edit Details\n",
      "Author:  Pramoedya Ananta Toer\n",
      "Rating Value:  \n",
      "  3.93\n",
      "\n",
      "Rating Count:  \n",
      "  1,386\n",
      "  ratings\n",
      "\n",
      "Plot:  \"...Kartini tidak punya massa, apalagi uang. Yang dipunyai Kartini adalah kepekaan dan keprihatinan dan ia tulislah segala-gala perasaannya yang tertekan itu. Dan hasilnya luar biasa, selain melambungkan nama Kartini, suaranya bisa terdengar sampai jauh, bahkan sampai ke negeri asal dan akar segala kehancuran manusia Pribumi...\"\n",
      "Number of Pages:  304 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        2000\n",
      "         by Hasta Mitra\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      Claimed by the Highlander\n",
      "\n",
      "Series:  \n",
      "        (Highlander #2)\n",
      "\n",
      "Author:  Julianne MacLean\n",
      "Rating Value:  \n",
      "  4.04\n",
      "\n",
      "Rating Count:  \n",
      "  4,512\n",
      "  ratings\n",
      "\n",
      "Plot:  With his tawny mane, battle-hewn brawn, and ferocious roar, Angus \"The Lion\" MacDonald is the most fearsome warrior Lady Gwendolen has ever seenâ€”and she is his most glorious conquest. Captured in a s\n",
      "Number of Pages:  319 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        March 29th 2011\n",
      "         by St. Martin's Paperbacks\n",
      "\n",
      "      \n",
      "Title:  \n",
      "      Chasers\n",
      "\n",
      "Series:  \n",
      "        (Alone #1)\n",
      "\n",
      "Author:  James  Phelan\n",
      "Rating Value:  \n",
      "  3.53\n",
      "\n",
      "Rating Count:  \n",
      "  1,167\n",
      "  ratings\n",
      "\n",
      "Plot:  \n",
      "Number of Pages:  247 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        November 2010\n",
      "         by Kensington Publishing Corp.\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      A Chalice of Wind\n",
      "\n",
      "Series:  \n",
      "        (Balefire #1)\n",
      "\n",
      "Author:  Cate Tiernan\n",
      "Rating Value:  \n",
      "  3.88\n",
      "\n",
      "Rating Count:  \n",
      "  2,607\n",
      "  ratings\n",
      "\n",
      "Plot:  Separated since birth, 17-year-old twins Thais and Clio unexpectedly meet in New Orleans where they seem to be pursued by a coven of witches who want to harness the twins' magical powers for its own ends.\n",
      "Number of Pages:  256 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        August 18th 2005\n",
      "         by Razorbill\n",
      "\n",
      "      \n",
      "Title:  \n",
      "      The Greenlanders\n",
      "\n",
      "Series:  Edit Details\n",
      "Author:  Jane Smiley\n",
      "Rating Value:  \n",
      "  3.90\n",
      "\n",
      "Rating Count:  \n",
      "  2,370\n",
      "  ratings\n",
      "\n",
      "Plot:  Pulitzer Prize winner and bestselling author Jane Smileyâ€™s  is an enthralling novel in the epic tradition of the old Norse sagas. Set in the fourteenth century in Europeâ€™s most far-flung outpost, a land of glittering fjords, blasting winds, sun-warmed meadows, and high, dark mountains,  is the story of one familyâ€“proud landowner Asgeir Gunna\n",
      "Number of Pages:  608 pages\n",
      "Publishing Date:  \n",
      "            Published\n",
      "        September 13th 2005\n",
      "         by Anchor\n",
      "\n",
      "            \n",
      "Title:  \n",
      "      Horatio Hornblower 1 - 11.\n",
      "\n",
      "Series:  \n",
      "        (Hornblower Saga: Chronological Order #1-11 box)\n",
      "\n",
      "Author:  C.S. Forester\n",
      "Rating Value:  \n",
      "  4.43\n",
      "\n",
      "Rating Count:  \n",
      "  1,591\n",
      "  ratings\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-815b6e6b875a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rating Value: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"span\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ratingValue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rating Count: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gr-hyperlink\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"#other_reviews\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Plot: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of Pages: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"span\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"numberOfPages\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Publishing Date: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"row\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Exercise 1.3\n",
    "\n",
    "import codecs\n",
    "\n",
    "page = 151\n",
    "\n",
    "i = 1 #book_id\n",
    "\n",
    "while (page <= 151):\n",
    "    #let's move to the correct directory --> the directory associated to the current page\n",
    "    directory = \"HTMLSources_Page\"+str(page)\n",
    "    parent_dir = \"/home/lorenzo/Documents/UniversitÃ /1Â° Term/Algorithmic Methods of Data Mining/LAB/Homeworks/HW3\"\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    os.chdir(path)\n",
    "    \n",
    "    while (i <= 100):#each page contains 100 books\n",
    "    \n",
    "        filename = \"Book\"+str(i)+\"_Page\"+str(page)\n",
    "        #print(filename)\n",
    "    \n",
    "        #now I need to read the stored locally html files\n",
    "        file = codecs.open(filename, 'r', 'utf-8')\n",
    "        document = BeautifulSoup(file.read(), features=\"lxml\") #\"document\" contains the html text of the corresp file\n",
    "        \n",
    "        print(\"Title: \",document.find_all(\"h1\", id=\"bookTitle\", class_=\"gr-h1 gr-h1--serif\", itemprop=\"name\")[0].contents[0])\n",
    "        print(\"Series: \",document.find_all(\"a\", class_=\"greyText\")[0].contents[0])\n",
    "        print(\"Author: \",document.find_all(\"span\", itemprop=\"name\")[0].contents[0])\n",
    "        print(\"Rating Value: \",document.find_all(\"span\", itemprop=\"ratingValue\")[0].contents[0])\n",
    "        print(\"Rating Count: \",document.find_all(\"a\", class_=\"gr-hyperlink\", href=\"#other_reviews\")[0].contents[2])\n",
    "        print(\"Plot: \", ' '.join([c for c in document.find_all('div', id=\"description\")[0].contents[1].contents if isinstance(c, str)]))\n",
    "        print(\"Number of Pages: \",document.find_all(\"span\", itemprop=\"numberOfPages\")[0].contents[0])\n",
    "        print(\"Publishing Date: \", document.find_all(\"div\", class_=\"row\")[1].contents[0])\n",
    "        #print(\"Characters: \", document.find_all(\"a\", href = href.split(\"/\")) if href[0] == \"characters\") ###WRONG! \n",
    "        #SETTING\n",
    "        \n",
    "        #description = ' '.join([c for c in soup.find_all('div', id=\"description\")[0].contents[1].contents if isinstance(c, str)])\n",
    "        \n",
    "        i+=1 #increment book_id\n",
    "    \n",
    "    page += 1 #increment page\n",
    "        \n",
    "    os.chdir('../') #back to the parent working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<link href=\"https://www.goodreads.com/book/show/510569.The_Greek_Myths\" rel=\"canonical\"/>\n",
      "<link href=\"https://www.goodreads.com/book/show/91563.The_Measure_of_a_Man\" rel=\"canonical\"/>\n",
      "<link href=\"https://www.goodreads.com/book/show/52917242-silent-pantheon\" rel=\"canonical\"/>\n",
      "<link href=\"https://www.goodreads.com/book/show/4224060-the-element\" rel=\"canonical\"/>\n",
      "<link href=\"https://www.goodreads.com/book/show/26831901-the-person-controller\" rel=\"canonical\"/>\n",
      "<link href=\"https://www.goodreads.com/book/show/169878.The_Grand_Tour\" rel=\"canonical\"/>\n",
      "<link href=\"https://www.goodreads.com/book/show/19398.Complete_Shorter_Fiction\" rel=\"canonical\"/>\n",
      "<link href=\"https://www.goodreads.com/book/show/1420762.The_Rosary\" rel=\"canonical\"/>\n",
      "<link href=\"https://www.goodreads.com/book/show/289643.Sunrise\" rel=\"canonical\"/>\n",
      "<link href=\"https://www.goodreads.com/book/show/16856.Flappers_and_Philosophers\" rel=\"canonical\"/>\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.3\n",
    "\n",
    "\n",
    "\n",
    "from langdetect import detect\n",
    "from textblob import TextBlob\n",
    "#function to parse the html pages\n",
    "def parse_pages(parent_dir):\n",
    "\n",
    "    '''\n",
    "    function to parse the downloded pages and take the infos we need\n",
    "    input: parent_dir with the downloaded pages\n",
    "    output: .tsv files\n",
    "    '''\n",
    "    article = [] #to create .tsv file\n",
    "    parent_dir = \"/home/lorenzo/Documents/UniversitÃ /1Â° Term/Algorithmic Methods of Data Mining/LAB/Homeworks/HW3\"\n",
    "    \n",
    "    p = 151        #pages, starting from 151\n",
    "    n = 1\n",
    "    while (p<=151): #we start opening the folder related to a specific page\n",
    "        directory = \"HTMLSources_Page\"+str(p) #directory of the page\n",
    "        path = os.path.join(parent_dir, directory) #create path\n",
    "        os.chdir(path)\n",
    "        \n",
    "        book_id = 1\n",
    "        \n",
    "        #book id per page, starting from 1\n",
    "        while(book_id <= 10):\n",
    "            \n",
    "            book = \"Book\"+str(book_id)+\"_\"+\"Page\"+str(p)\n",
    "            file = open(book, 'r')\n",
    "            html_doc =  BeautifulSoup(file.read(), features=\"lxml\")\n",
    "    \n",
    "            #Infos we want to know\n",
    "    \n",
    "            bookTitle = html_doc.find_all('h1')[0].contents[0]\n",
    "            bookTitle = bookTitle.split('\\n')[1].strip()\n",
    "            article.append(bookTitle)\n",
    "    \n",
    "    \n",
    "            bookAuthors = html_doc.find_all('span', itemprop=\"name\")[0].contents[0]\n",
    "            article.append(bookAuthors)\n",
    "    \n",
    "            bookSeries = html_doc.find_all('a', class_=\"greyText\")[0].contents[0]\n",
    "            #print(bookSeries)\n",
    "            if bookSeries == 'Edit Details':\n",
    "                bookSeries = ''\n",
    "                article.append(bookSeries)\n",
    "            else:\n",
    "                bookSeries = bookSeries.split('\\n')[1].strip()\n",
    "                article.append(bookSeries)\n",
    "            #print(bookSeries)\n",
    "            \n",
    "            \n",
    "    \n",
    "            ratingValue = html_doc.find_all('span', itemprop=\"ratingValue\")[0].contents[0]\n",
    "            ratingValue = ratingValue.split('\\n')[1].strip()\n",
    "            article.append(ratingValue)\n",
    "    \n",
    "            ratingCount = html_doc.find_all('a', href=\"#other_reviews\")[0].contents[2]\n",
    "            ratingCount = ratingCount.split('\\n')[1].strip()\n",
    "            article.append(ratingCount)\n",
    "    \n",
    "            reviewCount = html_doc.find_all('a', href=\"#other_reviews\")[1].contents[2]\n",
    "            reviewCount = reviewCount.split('\\n')[1].strip()\n",
    "            article.append(reviewCount)\n",
    "    \n",
    "            if (html_doc.find_all('div', {id : \"description\"})):\n",
    "                Plot = ' '.join([c for c in html_doc.find_all('div', id=\"description\")[0].contents[1].contents if isinstance(c, str)])\n",
    "            else:\n",
    "                Plot = \"   \"\n",
    "            article.append(Plot)\n",
    "            \n",
    "            if (html_doc.find_all('span', {'itemprop' : \"numberOfPages\"})):      \n",
    "                NumberofPages = html_doc.find_all('span', itemprop=\"numberOfPages\")[0].contents[0]\n",
    "                NumberofPages = NumberofPages.split(' ')[0]\n",
    "            else:\n",
    "                NumberofPages = ''\n",
    "            article.append(NumberofPages)\n",
    "            \n",
    "            if (html_doc.find_all('div', {'class' : \"row\"})[1].contents[0]):\n",
    "                PublishingDate = html_doc.find_all('div', class_=\"row\")[1].contents[0]\n",
    "                if (len(PublishingDate.split('\\n')) >= 3):\n",
    "                    PublishingDate = PublishingDate.split('\\n')[2].strip()\n",
    "                else:\n",
    "                    PublishingDate = \"\"\n",
    "            else:\n",
    "                PublishingDate = \"\"    \n",
    "            article.append(PublishingDate)\n",
    "            \n",
    "            if html_doc.find_all('a', {'href' : re.compile(r'/characters')}):\n",
    "                Characters = ','.join([item.text for item in  html_doc.find_all('a', href = re.compile(r'/characters'))])\n",
    "            else:\n",
    "                Characters = \"\"\n",
    "            article.append(Characters)\n",
    "            \n",
    "            if html_doc.find_all('a', {'href' : re.compile(r'/places')}):\n",
    "                Setting = ' '.join([item.text for item in  html_doc.find_all('a', href = re.compile(r'/places'))]) \n",
    "            else:\n",
    "                Setting = \"\"\n",
    "            article.append(Setting)\n",
    "            \n",
    "            Url = html_doc.find_all('link')[0]\n",
    "            #Url = html_doc.get('href')\n",
    "            #Url = \"https://www.goodreads.com/\"+Url\n",
    "            print(Url)\n",
    "            article.append(Url)\n",
    "    \n",
    "            #Url = html_doc.find_all('span', itemprop=\"name\")[0].contents[0]\n",
    "            #print(Url)\n",
    "            lang = TextBlob(Plot)\n",
    "\n",
    "    \n",
    "            if lang.detect_language() == 'eng' or Plot==\"   \": \n",
    "                path = \"/home/lorenzo/Documents/UniversitÃ /1Â° Term/Algorithmic Methods of Data Mining/LAB/Homeworks/HW3/Articles\"\n",
    "            #name_article = \"articles.tsv\"\n",
    "                name_article = \"article_\"+str(n)+\".tsv\"\n",
    "    \n",
    "                with open(os.path.join(path,name_article), 'w', newline='') as f_output:\n",
    "                    tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "                    tsv_output.writerow(article)\n",
    "                    n += 1\n",
    "                    article.clear()\n",
    "                #article.append()\n",
    "                \n",
    "                book_id +=1\n",
    "        p +=1\n",
    "\n",
    "#####################################################        \n",
    "article = [] #to create .tsv file\n",
    "parent_dir = \"/home/lorenzo/Documents/UniversitÃ /1Â° Term/Algorithmic Methods of Data Mining/LAB/Homeworks/HW3\"\n",
    "parse_pages(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Finding Perfect</th>\n",
       "      <th>Susan Mallery</th>\n",
       "      <th>(Fool's Gold #3)</th>\n",
       "      <th>4.07</th>\n",
       "      <th>11,648</th>\n",
       "      <th>512</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>346</th>\n",
       "      <th>August 31st 2010</th>\n",
       "      <th>Pia Oâ€™Brian,Raoul Moreno</th>\n",
       "      <th>Fool's Gold, California</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Finding Perfect, Susan Mallery, (Fool's Gold #3), 4.07, 11,648, 512, Unnamed: 6, 346, August 31st 2010, Pia Oâ€™Brian,Raoul Moreno, Fool's Gold, California]\n",
       "Index: []"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/home/lorenzo/Documents/UniversitÃ /1Â° Term/Algorithmic Methods of Data Mining/LAB/Homeworks/HW3/Articles/article_100.tsv\",delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lorenzo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk #Natural Language ToolKit\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = pd.read_csv(\"/home/lorenzo/Documents/UniversitÃ /1Â° Term/Algorithmic Methods of Data Mining/LAB/Homeworks/HW3/Articles/article_1.tsv\",delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Plot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6129d1e01b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Plot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Plot'"
     ]
    }
   ],
   "source": [
    "article['Plot'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove useless charachters from all TSVs\n",
    "i = 1\n",
    "n = 1\n",
    "\n",
    "dataset = []\n",
    "\n",
    "while i<=15:\n",
    "    article = pd.read_csv(\"/home/lorenzo/Documents/UniversitÃ /1Â° Term/Algorithmic Methods of Data Mining/LAB/Homeworks/HW3/Articles/article_\"+str(i)+\".tsv\",delimiter='\\t',encoding='utf-8')\n",
    "    article = article.columns\n",
    "    tokens_list = []\n",
    "    for k in range(len(article)):\n",
    "        removeSpecialChars = \"\".join(c for c in article[k] if c not in (\"/\",\"<\",\">\",\"|\",\"`\",\"~\",\"-\",\"=\",\"_\",\"+\",\"?\", \",\", \".\", \";\", \":\", \"!\", \"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"(\",\")\",\"[\",\"]\",\"{\",\"}\"))\n",
    "        words = removeSpecialChars\n",
    "        tokens = nltk.word_tokenize(words)\n",
    "        def_string = ' '.join(el for el in tokens)\n",
    "        tokens_list.append(def_string)\n",
    "    \n",
    "    path = \"/home/lorenzo/Documents/UniversitÃ /1Â° Term/Algorithmic Methods of Data Mining/LAB/Homeworks/HW3/Articles\"\n",
    "    name_article = \"article_\"+str(i)+\".tsv\"\n",
    "    \n",
    "    with open(os.path.join(path,name_article), 'w', newline='') as f_output:\n",
    "        tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "        tsv_output.writerow(tokens_list)\n",
    "    \n",
    "    tokens_list.clear()\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1\n",
    "\n",
    "while i<=15:\n",
    "    article = pd.read_csv(\"/home/lorenzo/Documents/UniversitÃ /1Â° Term/Algorithmic Methods of Data Mining/LAB/Homeworks/HW3/Articles/article_\"+str(i)+\".tsv\",delimiter='\\t',encoding='utf-8')\n",
    "    article = article.columns\n",
    "    tokens_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
